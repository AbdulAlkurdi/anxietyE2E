{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RxQoMxAbO9Bc","executionInfo":{"status":"ok","timestamp":1679916995807,"user_tz":300,"elapsed":22699,"user":{"displayName":"Xulin Fan","userId":"05250765126197761843"}},"outputId":"4596b2a3-cbd2-47da-e9cc-f5954df35fbf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os \n","os.chdir(\"drive/MyDrive/torch_FCN\")"],"metadata":{"id":"Whu7ZBHifi8s"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8cuQKYufOyP-"},"outputs":[],"source":["import numpy as np\n","def sliding_window(signal, win_len, shift):\n","\n","    n_windows = int((signal.shape[0] - win_len) / shift) + 1\n","    samples = []\n","    \n","    for i in range(n_windows):\n","        samples.append(signal[i * shift: i * shift + win_len])\n","    \n","    samples = np.stack(samples)\n","    \n","    return samples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cl40tjZiOyQA"},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler\n","def minmaxscaling(array):\n","    scaler = MinMaxScaler()\n","    scaler.fit(array)\n","    result = scaler.transform(array)\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eHKKT9v6OyQD"},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","import torch\n","import pickle\n","\n","class WESADDataset(Dataset):\n","\n","    def __init__(self, path):\n","        \"\"\"\n","        Args:\n","            csv_file (string): Path to the csv file with annotations.\n","            root_dir (string): Directory with all the images.\n","            transform (callable, optional): Optional transform to be applied\n","                on a sample.\n","        \"\"\"\n","        with open(path, 'rb') as file:\n","            trainset = pickle.load(file, encoding='latin1')\n","\n","        self.ACCx = torch.tensor(trainset['ACCx'])\n","        self.ACCy = torch.tensor(trainset['ACCy'])\n","        self.ACCz = torch.tensor(trainset['ACCz'])\n","        self.EDA = torch.tensor(trainset['EDA'])\n","        self.TEMP = torch.tensor(trainset['TEMP'])\n","        self.BVP = torch.tensor(trainset['BVP'])\n","        self.Ys = torch.tensor(trainset['Ys'])\n","        \n","        \n","    def __len__(self):\n","        return len(self.ACCx)\n","\n","    def __getitem__(self, idx):\n","        return self.ACCx[idx], self.ACCy[idx], self.ACCz[idx], self.EDA[idx], self.TEMP[idx], self.BVP[idx], self.Ys[idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I4-NmKwZOyQE"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class ConvLayers(nn.Module):\n","    def __init__(self):\n","        super(ConvLayers, self).__init__()\n","        self.conv1 = nn.Conv1d(1, 128, 8, padding='same')\n","        self.bn1 = nn.BatchNorm1d(128)\n","        self.conv2 = nn.Conv1d(128, 256, 5, padding='same')\n","        self.bn2 = nn.BatchNorm1d(256)\n","        self.conv3 = nn.Conv1d(256, 128, 3, padding='same')\n","        self.bn3 = nn.BatchNorm1d(128)\n","        self.pool = nn.AdaptiveAvgPool1d(1)\n","        \n","    def forward(self, x):\n","        \n","        x = x.float()\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = F.relu(self.bn2(self.conv2(x)))\n","        x = F.relu(self.bn3(self.conv3(x)))\n","        return self.pool(x).squeeze(-1)\n","    \n","class FCN_model(nn.Module):\n","    def __init__(self, input_channels):\n","        super(FCN_model, self).__init__()\n","        # Needs code here\n","        self.num_channel = input_channels\n","        self.convLayersList = []\n","        for i in range(input_channels):\n","            self.convLayersList.append(ConvLayers().to(device))\n","        self.fc = nn.Linear(128 * input_channels, 2)\n","\n","    def forward(self, accx, accy, accz, eda, temp, bvp):\n","        # Needs code here\n","        accx_out = self.convLayersList[0](accx)\n","        accy_out = self.convLayersList[1](accy)\n","        accz_out = self.convLayersList[2](accz)\n","        eda_out = self.convLayersList[3](eda)\n","        temp_out = self.convLayersList[4](temp)\n","        bvp_out = self.convLayersList[5](bvp)\n","        multi_modal_out = torch.cat([accx_out, accy_out,\n","                                     accz_out, eda_out,\n","                                     temp_out, bvp_out], dim=-1)\n","        \n","        return self.fc(multi_modal_out)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RpvKrWXXOyQF"},"outputs":[],"source":["training_set = WESADDataset('train.pkl')\n","validation_set = WESADDataset('test.pkl')\n","train_loader = DataLoader(training_set, batch_size=128,\n","                        shuffle=True, num_workers=2)\n","val_loader = DataLoader(validation_set, batch_size=128,\n","                        shuffle=True, num_workers=2)"]},{"cell_type":"code","source":["len(training_set) + len(validation_set)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EQX_gH5JtfND","executionInfo":{"status":"ok","timestamp":1679277492084,"user_tz":300,"elapsed":134,"user":{"displayName":"Xulin Fan","userId":"05250765126197761843"}},"outputId":"588eccc7-b9f8-4fe8-d2f1-a72eeaf11038"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1105"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CbMid95IOyQF","executionInfo":{"status":"ok","timestamp":1679917145912,"user_tz":300,"elapsed":125761,"user":{"displayName":"Xulin Fan","userId":"05250765126197761843"}},"outputId":"7bc53d53-3661-4d77-b683-76b7ce88689b"},"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py:309: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)\n","  return F.conv1d(input, weight, bias, self.stride,\n"]},{"output_type":"stream","name":"stdout","text":["\n","epoch 0 have loss 0.5779998898506165\n"]},{"output_type":"stream","name":"stderr","text":["\r  5%|▌         | 1/20 [00:12<03:48, 12.03s/it]"]},{"output_type":"stream","name":"stdout","text":["TP: 20 FP: 0 TN: 154 FN: 49 F1: 0.44943820224719105\n","\n","epoch 1 have loss 0.3808300495147705\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 2/20 [00:17<02:26,  8.13s/it]"]},{"output_type":"stream","name":"stdout","text":["TP: 38 FP: 2 TN: 152 FN: 31 F1: 0.6972477064220184\n","\n","epoch 2 have loss 0.28784826397895813\n"]},{"output_type":"stream","name":"stderr","text":["\r 15%|█▌        | 3/20 [00:22<01:58,  6.94s/it]"]},{"output_type":"stream","name":"stdout","text":["TP: 43 FP: 6 TN: 148 FN: 26 F1: 0.7288135593220338\n","\n","epoch 3 have loss 0.2308165729045868\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 4/20 [00:28<01:42,  6.40s/it]"]},{"output_type":"stream","name":"stdout","text":["TP: 39 FP: 4 TN: 150 FN: 30 F1: 0.6964285714285715\n","\n","epoch 4 have loss 0.20836016535758972\n"]},{"output_type":"stream","name":"stderr","text":["\r 25%|██▌       | 5/20 [00:34<01:31,  6.10s/it]"]},{"output_type":"stream","name":"stdout","text":["TP: 43 FP: 3 TN: 151 FN: 26 F1: 0.7478260869565218\n","\n","epoch 5 have loss 0.18441854417324066\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 6/20 [00:39<01:22,  5.93s/it]"]},{"output_type":"stream","name":"stdout","text":["TP: 44 FP: 9 TN: 145 FN: 25 F1: 0.7213114754098361\n","\n","epoch 6 have loss 0.17365054786205292\n"]},{"output_type":"stream","name":"stderr","text":["\r 35%|███▌      | 7/20 [00:45<01:17,  5.96s/it]"]},{"output_type":"stream","name":"stdout","text":["TP: 44 FP: 7 TN: 147 FN: 25 F1: 0.7333333333333333\n","\n","epoch 7 have loss 0.17425404489040375\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 8/20 [00:51<01:10,  5.89s/it]"]},{"output_type":"stream","name":"stdout","text":["TP: 43 FP: 6 TN: 148 FN: 26 F1: 0.7288135593220338\n","\n","epoch 8 have loss 0.16291534900665283\n"]},{"output_type":"stream","name":"stderr","text":["\r 45%|████▌     | 9/20 [00:57<01:04,  5.84s/it]"]},{"output_type":"stream","name":"stdout","text":["TP: 42 FP: 6 TN: 148 FN: 27 F1: 0.717948717948718\n","\n","epoch 9 have loss 0.1587778776884079\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 10/20 [01:03<00:58,  5.84s/it]"]},{"output_type":"stream","name":"stdout","text":["TP: 44 FP: 8 TN: 146 FN: 25 F1: 0.7272727272727273\n","\n","epoch 10 have loss 0.15724293887615204\n"]},{"output_type":"stream","name":"stderr","text":["\r 55%|█████▌    | 11/20 [01:08<00:52,  5.85s/it]"]},{"output_type":"stream","name":"stdout","text":["TP: 45 FP: 9 TN: 145 FN: 24 F1: 0.7317073170731708\n","\n","epoch 11 have loss 0.15034165978431702\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 12/20 [01:14<00:47,  5.88s/it]"]},{"output_type":"stream","name":"stdout","text":["TP: 44 FP: 8 TN: 146 FN: 25 F1: 0.7272727272727273\n","\n","epoch 12 have loss 0.14732299745082855\n"]},{"output_type":"stream","name":"stderr","text":["\r 65%|██████▌   | 13/20 [01:20<00:40,  5.85s/it]"]},{"output_type":"stream","name":"stdout","text":["TP: 43 FP: 9 TN: 145 FN: 26 F1: 0.7107438016528926\n","\n","epoch 13 have loss 0.14750607311725616\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 14/20 [01:26<00:35,  5.86s/it]"]},{"output_type":"stream","name":"stdout","text":["TP: 44 FP: 10 TN: 144 FN: 25 F1: 0.7154471544715448\n","\n","epoch 14 have loss 0.1410067230463028\n"]},{"output_type":"stream","name":"stderr","text":["\r 75%|███████▌  | 15/20 [01:32<00:29,  5.84s/it]"]},{"output_type":"stream","name":"stdout","text":["TP: 43 FP: 9 TN: 145 FN: 26 F1: 0.7107438016528926\n","\n","epoch 15 have loss 0.13250869512557983\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 16/20 [01:37<00:23,  5.79s/it]"]},{"output_type":"stream","name":"stdout","text":["TP: 44 FP: 11 TN: 143 FN: 25 F1: 0.7096774193548386\n","\n","epoch 16 have loss 0.1455996334552765\n"]},{"output_type":"stream","name":"stderr","text":["\r 85%|████████▌ | 17/20 [01:43<00:17,  5.76s/it]"]},{"output_type":"stream","name":"stdout","text":["TP: 45 FP: 13 TN: 141 FN: 24 F1: 0.7086614173228347\n","\n","epoch 17 have loss 0.13311244547367096\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 18/20 [01:49<00:11,  5.73s/it]"]},{"output_type":"stream","name":"stdout","text":["TP: 43 FP: 12 TN: 142 FN: 26 F1: 0.6935483870967741\n","\n","epoch 18 have loss 0.13031573593616486\n"]},{"output_type":"stream","name":"stderr","text":["\r 95%|█████████▌| 19/20 [01:55<00:05,  5.73s/it]"]},{"output_type":"stream","name":"stdout","text":["TP: 45 FP: 12 TN: 142 FN: 24 F1: 0.7142857142857143\n","\n","epoch 19 have loss 0.1415025293827057\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [02:00<00:00,  6.03s/it]"]},{"output_type":"stream","name":"stdout","text":["TP: 46 FP: 14 TN: 140 FN: 23 F1: 0.7131782945736433\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["from tqdm import tqdm\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = FCN_model(6).to(device)\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","\n","# Train the model\n","for epoch in tqdm(range(20)):\n","    losses = []\n","    for accx, accy, accz, eda, temp, bvp, label in train_loader:\n","        accx = accx.permute(0, 2, 1).to(device)\n","        accy = accy.permute(0, 2, 1).to(device)\n","        accz = accz.permute(0, 2, 1).to(device)\n","        eda = eda.permute(0, 2, 1).to(device)\n","        temp = temp.permute(0, 2, 1).to(device)\n","        bvp = bvp.permute(0, 2, 1).to(device)\n","        label = label.to(device)\n","        \n","        optimizer.zero_grad()\n","        pred = model(accx, accy, accz, eda, temp, bvp)\n","        #print(label)\n","        loss = loss_fn(pred, label)\n","        #print(loss)\n","        loss.backward()\n","        optimizer.step()\n","        losses.append(loss.detach().cpu().numpy())\n","    print(\"\\nepoch {} have loss {}\".format(epoch, np.mean(losses)))\n","    \n","    with torch.no_grad():\n","        TP = 0\n","        FP = 0\n","        TN = 0\n","        FN = 0\n","        for accx, accy, accz, eda, temp, bvp, label in val_loader:\n","            accx = accx.permute(0, 2, 1).to(device)\n","            accy = accy.permute(0, 2, 1).to(device)\n","            accz = accz.permute(0, 2, 1).to(device)\n","            eda = eda.permute(0, 2, 1).to(device)\n","            temp = temp.permute(0, 2, 1).to(device)\n","            bvp = bvp.permute(0, 2, 1).to(device)\n","            label = label.to(device)\n","\n","            pred = model(accx, accy, accz, eda, temp, bvp)\n","            logits = pred.argmax(-1)\n","            TP += torch.logical_and(label == 1, logits == 1).sum().detach().cpu().numpy()\n","            FP += torch.logical_and(label == 0, logits == 1).sum().detach().cpu().numpy()\n","            TN += torch.logical_and(label == 0, logits == 0).sum().detach().cpu().numpy()\n","            FN += torch.logical_and(label == 1, logits == 0).sum().detach().cpu().numpy()\n","        \n","        P = TP / (TP + FP)\n","        R = TP / (TP + FN)\n","        F1 = (2 * P * R) / (P + R)\n","\n","        print('TP:', TP, 'FP:', FP, 'TN:', TN, 'FN:', FN, 'F1:', F1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pSwezPQmOyQG","executionInfo":{"status":"ok","timestamp":1679275593000,"user_tz":300,"elapsed":716,"user":{"displayName":"Xulin Fan","userId":"05250765126197761843"}},"outputId":"cbcca3a5-e2af-4723-c207-f43c57ad5a62"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["2318"]},"metadata":{},"execution_count":25}],"source":["len(training_set)"]},{"cell_type":"code","source":["len(validation_set)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LBWEPH-6oAel","executionInfo":{"status":"ok","timestamp":1679275611584,"user_tz":300,"elapsed":460,"user":{"displayName":"Xulin Fan","userId":"05250765126197761843"}},"outputId":"a2b5337c-e3d6-4de0-d6f9-9a836feaf9bd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["556"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["redware_set = WESADDataset('s14.pkl')\n","redware_loader = DataLoader(redware_set, batch_size=128,\n","                        shuffle=True, num_workers=2)"],"metadata":{"id":"ilKA4c6KoCoZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with torch.no_grad():\n","    TP = 0\n","    FP = 0\n","    TN = 0\n","    FN = 0\n","    for accx, accy, accz, eda, temp, bvp, label in redware_loader:\n","        accx = accx.permute(0, 2, 1).to(device)\n","        accy = accy.permute(0, 2, 1).to(device)\n","        accz = accz.permute(0, 2, 1).to(device)\n","        eda = eda.permute(0, 2, 1).to(device)\n","        temp = temp.permute(0, 2, 1).to(device)\n","        bvp = bvp.permute(0, 2, 1).to(device)\n","        label = label.to(device)\n","\n","        pred = model(accx, accy, accz, eda, temp, bvp)\n","        logits = pred.argmax(-1)\n","        TP += torch.logical_and(label == 1, logits == 1).sum().detach().cpu().numpy()\n","        FP += torch.logical_and(label == 0, logits == 1).sum().detach().cpu().numpy()\n","        TN += torch.logical_and(label == 0, logits == 0).sum().detach().cpu().numpy()\n","        FN += torch.logical_and(label == 1, logits == 0).sum().detach().cpu().numpy()\n","    \n","    P = TP / (TP + FP)\n","    R = TP / (TP + FN)\n","    F1 = (2 * P * R) / (P + R)\n","\n","    print('TP:', TP, 'FP:', FP, 'TN:', TN, 'FN:', FN, 'P:', P, 'R:', R, 'F1:', F1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yPZJmBXX3eKy","executionInfo":{"status":"ok","timestamp":1679917771011,"user_tz":300,"elapsed":10578,"user":{"displayName":"Xulin Fan","userId":"05250765126197761843"}},"outputId":"487b534b-bca5-4696-a60d-c36e16ce4968"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["TP: 303 FP: 587 TN: 3574 FN: 668 P: 0.3404494382022472 R: 0.3120494335736354 F1: 0.32563138097796884\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"3ObcFGBp4U--"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}